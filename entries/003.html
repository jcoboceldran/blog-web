<!DOCTYPE html>
<html lang='en'>
<head>
    <meta charset='UTF-8'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0'>
    <meta http-equiv='X-UA-Compatible' content='ie=edge'>
    <link rel='preconnect' href='https://fonts.googleapis.com'>
    <link rel='preconnect' href='https://fonts.gstatic.com' crossorigin>
    <link href='https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap' rel='stylesheet'>
    <link href='../resources/index/logo.png' rel='icon' type='png'>
    <title>003 - Juan Cobo</title>
    <link rel='stylesheet' href='../styles/main_style.css'>
    <link rel='stylesheet' href='../styles/entry_style.css'>
</head>
<body>
    <header>
        <nav>
            <img src='../resources/index/logo.png' alt='favicon'>
            <a href='../index.html'>Back ↖</a>
        </nav>
    </header>
    <section>
        <h1>A very pessimistic prediction on the future of AI. Information apocalypse.</h1>
        <p>Maybe the title of this entry is a bit of an exaggeration, but it is almost indisputable that a major shift in society is happening. With the publication of 'Attention is all you need' by Ashish Vaswani et al., a huge leap was made in AI performance and usability. Since then we have witnessed plenty of milestones in the AI field, the most well known being the release of ChatGPT 3 to the public, which became the fastest app to achieve 100 million users. The given definition for an apocalypse by the Cambridge Dictionary is 'a very serious event resulting in great destruction and change'. But what can AI actually destroy and change in human society?</p>
        <p>It might be hard to grasp how AI can really destroy or change anything with its current form. At the end of the day is just a program that takes some words and outputs some other words. If we want to get a bit more technical it can be elegantly defined as the mapping of any input vector (the words you input) to some output vector (the words the AI outputs). However, it is so much more than that, this mapping of vectors gets incredibly complex, and it doesn’t only match words to other words, AI scientists quickly discovered that this mapping works on almost any multimedia form that can be presented as a vector, including images, video, audio, etcetera. Now the possibilities for what AI can do broadens, therefore the chances of destruction and change do as well.</p>
        <p>There are many plausible ways in which AI can cause damage, but in my opinion the most prevalent of those lies within the realm of entertainment. Generative AI gives us the chance to create beautiful art (maybe art is not the best name for it, but least beautiful multimedia), so now everyone could paint their own painting without knowing how to paint, compose their own songs without knowing how to play a single note, write charming poetry without  knowing how to rhyme. And most importantly,  we could create compelling and persuasive narratives about topics we know nothing about.  Disinformation and misinformation are already hugely important problems for society. The new possibilities that Generative AI offers us will only aggravate these problems, in unpredictable ways, if we misuse them.</p>
        <p>To clarify, disinformation is defined by Sadiq Muhammed and Saji K. Mathewas on 'The disaster of misinformation: a review of research in social media' as information that is fake or misleading and spreads intentionally. On the other hand,  misinformation is also the information that is fake or misleading but spreads unintentionally.</p>
        <p>So as I said before this is an already existing problem, but how does GenAI make it so much worse? To explain this I have to introduce a new term: 'Deepfakes', described in Wikipedia as 'synthetic media that has been digitally manipulated to replace one person's likeness convincingly with that of another', so in simpler terms, manipulating a picture, video, or sound track to appear as if it was someone else on it. This is a technique that is made much easier by modern day advancement in AI. The spreading of this allows for the mainstream public to spread both misinformation and disinformation in much  more detrimental ways.</p>
        <p>As different research shows, we are clearly not ready for this problem as it was before GenAI, now it will be way worse. We all are susceptible, and if we weren’t before we probably will be now. Many people get pretty much all the news from social media, especially the younger generation, and the older generation, which may be getting their news from some other outlets, but they are especially susceptible to deep fakes. Also nowadays even those other new outlets are spreading misinformation (because they are accidentally using bad sources) or disinformation (on a more conspiratory note, because they are trying to push false narratives). Either way this problem affects everyone in some way or another, as the truth becomes more and more hard to find between the lies.</p>
        <p>So how can this problem cause destruction and change? Misinformation and disinformation will only grow larger, in unexpected ways. 'Reliable information is to civic health what proper sanitation and potable water are to public health. A polluted information supply imperils our nation’s civic health' said Sam Wineburg, truthful information outlets are fundamental for a working society. A prominent example of how misinformation and disinformation can have an damaging impact on society and its well being is described in fore mentioned article : 'In India, during the initial stage of COVID-19, there was reportedly a surge in fake news linking the virus outbreak to a particular religious group. This disinformation spread gained media attention as it was widely shared on social media platforms. As a result of the targeting, it eventually translated into physical violence and discriminatory treatment against members of the community in some of the Indian states.'</p>
        <p>But this example is prior to the AI leap, so let’s imagine for a moment the way in which new attacks could happen.  Say, for example, you want to make a subject lose its credibility before some important event, it would be as easy as creating a few deep fakes of said subject doing some legitimate activity (drugs, cheating scandal, racial slurs, etcetera), and release that into the public. This is something that would not be too complex to make with the progress of AI, and of course the subject could deny and claim the fakeness of the deep fakes, but the damage would be done, to a higher or lower extent. This is just one among many examples that can be hypothetically drawn, in the wrong hands way more severe attacks could be done.</p>
        <p>So to sum up the problem, basically the most popular information distribution center in the world (the internet), is losing all its credibility, and we are not catching up fast enough to realize this, or to adapt to it. And by the time we do, who knows what would have happened already?</p>
        <p>So, is apocalypse the right word?</p>       
    </section>
    <section>
        <h2>Links</h2>
        <article>
            <p class='links-title'>Email</p>
            <a href='mailto:jcoboceldran@gmail.com'>jcoboceldran@gmail.com ↗</a>
        </article>
        <article>
            <p>LinkedIn</p>
            <a href='https://www.linkedin.com/in/juan-cobo-celdr%C3%A1n/'>@juan-cobo-celdrán ↗</a>
        </article>
        <article>
            <p class='links-title'>Curriculum</p>
            <a href='resources/index/CV.pdf'class='links-subtitle'>pdf ↗</a>
        </article> 
    </section>
</body>
</html>